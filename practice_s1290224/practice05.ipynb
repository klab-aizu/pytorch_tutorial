{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddd598af3a8742309523b9165f97c313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bf667a88500445b85b17c67f0e1af92",
              "IPY_MODEL_d8fd9656d3ee4069abfd559e35b91dd7",
              "IPY_MODEL_a9f974adecf04f369141bc9a4290470d"
            ],
            "layout": "IPY_MODEL_36b2085a2c064fe5abcba268a24d561a"
          }
        },
        "9bf667a88500445b85b17c67f0e1af92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be57606dcea34a1cb4d0ab6a7a9b597d",
            "placeholder": "​",
            "style": "IPY_MODEL_8a6563662a394120931fad6689ed0dcd",
            "value": "100%"
          }
        },
        "d8fd9656d3ee4069abfd559e35b91dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45a44390a4964e2fbf1520fcb1d33b5f",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_740a40924b8d400eb689fad010406e1b",
            "value": 5
          }
        },
        "a9f974adecf04f369141bc9a4290470d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5099a2c86144414ab8001f48a9722c45",
            "placeholder": "​",
            "style": "IPY_MODEL_347c24ae0e4848748074131952e2c48c",
            "value": " 5/5 [00:11&lt;00:00,  2.40s/it]"
          }
        },
        "36b2085a2c064fe5abcba268a24d561a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be57606dcea34a1cb4d0ab6a7a9b597d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6563662a394120931fad6689ed0dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45a44390a4964e2fbf1520fcb1d33b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740a40924b8d400eb689fad010406e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5099a2c86144414ab8001f48a9722c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347c24ae0e4848748074131952e2c48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Get Data"
      ],
      "metadata": {
        "id": "cVYQVA-1ICiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6FVlmXhH5ZP",
        "outputId": "8cf7fbbc-a56a-4863-a592-5455367e89ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory going_modular/data already exists\n",
            "Downloading pizza steak sushi data\n",
            "Unzipping pizza_steak_sushi.zip  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Set up path for data\n",
        "data_path = Path(\"going_modular/data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the data path does not exist, create it\n",
        "if image_path.is_dir():\n",
        "  print(f\"Directory {data_path} already exists\")\n",
        "else:\n",
        "  print(f\"Directory {data_path} does not exit, creating one...\")\n",
        "  data_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "# Download pizza steak sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza steak sushi data\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip pizza steak sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza_steak_sushi.zip  \")\n",
        "  zip_ref.extractall(image_path)\n",
        "\n",
        "# Remove zip file\n",
        "os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create Datasets and DataLoaders (data_setup.py)"
      ],
      "metadata": {
        "id": "ijWHx0JbRTe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/data_setup.py\n",
        "\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir : str,\n",
        "    test_dir : str,\n",
        "    transform : transforms.Compose,\n",
        "    batch_size : int,\n",
        "    num_workers : int=NUM_WORKERS):\n",
        "\n",
        "    \"\"\"Creates training and testing DataLoaders.\n",
        "\n",
        "  Takes in a training directory and testing directory path and turns\n",
        "  them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
        "\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
        "    Where class_names is a list of the target classes.\n",
        "    Example usage:\n",
        "      train_dataloader, test_dataloader, class_names = \\\n",
        "        = create_dataloaders(train_dir=path/to/train_dir,\n",
        "                             test_dir=path/to/test_dir,\n",
        "                             transform=some_transform,\n",
        "                             batch_size=32,\n",
        "                             num_workers=4)\n",
        "  \"\"\"\n",
        "\n",
        "    # Datasets from image folders\n",
        "    train_data = datasets.ImageFolder(train_dir, transform = transform)\n",
        "    test_data = datasets.ImageFolder(test_dir, transform = transform)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = train_data.classes\n",
        "\n",
        "    # Dataloaders from datasets\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = True,\n",
        "        num_workers = num_workers,\n",
        "        pin_memory = True)\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size = batch_size,\n",
        "        shuffle = False,\n",
        "        num_workers = num_workers,\n",
        "        pin_memory = True)\n",
        "\n",
        "    return train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8stLt58dLKV2",
        "outputId": "9cb31098-77b2-431c-ef68-b2dc46518fa4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup"
      ],
      "metadata": {
        "id": "3kjQQSBJMGCw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Making a model(model_builder.py)"
      ],
      "metadata": {
        "id": "F6juSwXIRdTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/model_builder.py\n",
        "\"\"\"\n",
        "Contains PyTorch model code to instantiate a TinyVGG model.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"Creates the TinyVGG architecture.\n",
        "\n",
        "  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
        "  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
        "\n",
        "  Args:\n",
        "    input_shape: An integer indicating number of input channels.\n",
        "    hidden_units: An integer indicating number of hidden units between layers.\n",
        "    output_shape: An integer indicating number of output units.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape : int, hidden_units : int, output_shape : int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = input_shape,\n",
        "            out_channels = hidden_units,\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            padding = 0\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(\n",
        "            in_channels = hidden_units,\n",
        "            out_channels = hidden_units,\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            padding = 0\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size = 3, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size = 3, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units*13*13,\n",
        "                  out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "a9L_CtgCQj1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a18f05-76ea-4f21-f20f-a3e84593e9a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/going_modular/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from going_modular.going_modular import model_builder\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class_names = [\"pizza\", \"steak\", \"sushi\"]\n",
        "torch.manual_seed(42)\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape = 3,\n",
        "    hidden_units = 10,\n",
        "    output_shape = len(class_names)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "Kotv4YrARcBl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Creating train_step() and test_step() functions and train() to combine them"
      ],
      "metadata": {
        "id": "DVAYJGjaEeXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/engine.py\n",
        "\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def train_step(model : torch.nn.Module,\n",
        "               dataloader : torch.utils.data.DataLoader,\n",
        "               loss_fn : torch.nn.Module,\n",
        "               optimizer : torch.optim.Optimizer,\n",
        "               device : torch.device) -> Tuple[float, float]:\n",
        "  \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  Turns a target PyTorch model to training mode and then\n",
        "  runs through all of the required training steps (forward\n",
        "  pass, loss calculation, optimizer step).\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_acc). For example:\n",
        "\n",
        "    (0.1112, 0.8743)\n",
        "  \"\"\"\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Train loss and accuracy\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward propagation on the loss\n",
        "    loss.backward()\n",
        "\n",
        "    # Step the optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim = 1), dim = 1)\n",
        "    train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
        "\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model : torch.nn.Module,\n",
        "              dataloader : torch.utils.data.DataLoader,\n",
        "              loss_fn : torch.nn.Module,\n",
        "              device : torch.device) -> Tuple[float, float]:\n",
        "\n",
        "  # Put model on eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Test loss and accuracy\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # Forward pass\n",
        "      y_pred_logits = model(X)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_fn(y_pred_logits, y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      # Calculate accuracy\n",
        "      y_pred_label = torch.argmax(torch.softmax(y_pred_logits, dim = 1), dim = 1)\n",
        "      test_acc += (y_pred_label == y).sum().item() / len(y_pred_logits)\n",
        "\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "\n",
        "  return test_loss, test_acc\n",
        "\n",
        "def train(model : torch.nn.Module,\n",
        "          train_dataloader : torch.utils.data.DataLoader,\n",
        "          test_dataloader : torch.utils.data.DataLoader,\n",
        "          optimizer : torch.optim.Optimizer,\n",
        "          loss_fn : torch.nn.Module,\n",
        "          epochs : int,\n",
        "          device : torch.device) -> Dict[str, List]:\n",
        "  \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "  Passes a target PyTorch models through train_step() and test_step()\n",
        "  functions for a number of epochs, training and testing the model\n",
        "  in the same epoch loop.\n",
        "\n",
        "  Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "                 {train_loss: [2.0616, 1.0537],\n",
        "                  train_acc: [0.3945, 0.3945],\n",
        "                  test_loss: [1.2641, 1.5706],\n",
        "                  test_acc: [0.3400, 0.2973]}\n",
        "  \"\"\"\n",
        "  # Create empty dictionary\n",
        "  results = {\"train_loss\" : [],\n",
        "             \"train_acc\" : [],\n",
        "             \"test_loss\" : [],\n",
        "             \"test_acc\" : []}\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    # Train model\n",
        "    train_loss, train_acc = train_step(model = model,\n",
        "                                       dataloader = train_dataloader,\n",
        "                                       loss_fn = loss_fn,\n",
        "                                       optimizer = optimizer,\n",
        "                                       device = device)\n",
        "    # Test model\n",
        "    test_loss, test_acc = test_step(model = model,\n",
        "                                    dataloader = test_dataloader,\n",
        "                                    loss_fn = loss_fn,\n",
        "                                    device = device)\n",
        "\n",
        "    # Print what is happening\n",
        "    print(f\"Epoch: {epoch + 1}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, test_loss: {test_loss:.4f}, test_acc: {test_acc:.4f}\")\n",
        "\n",
        "    # Update dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfTUxtElEgUB",
        "outputId": "f4f8cd7c-11d3-47f8-e695-5dc6f448bd5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import engine"
      ],
      "metadata": {
        "id": "ccURTSp5PGnn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Creating a function to save the model (utils.py)"
      ],
      "metadata": {
        "id": "2JGhM2AtPhuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/utils.py\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model : torch.nn.Module,\n",
        "               target_dir : str,\n",
        "               model_name : str):\n",
        "\n",
        "  # Create target dictionary\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents = True,\n",
        "                   exist_ok = True)\n",
        "\n",
        "  # Create model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\"pt\")\n",
        "  model_save_path = target_dir_path / model_name\n",
        "\n",
        "  # Save the model state dict\n",
        "  print(f\"[INFO] saving model to {model_save_path}\")\n",
        "  torch.save(obj = model.state_dict(),\n",
        "             f = model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV5z7ABBPP_l",
        "outputId": "76698913-165d-4389-ecf5-832723078050"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Train, evaluate and save the model (train.py)"
      ],
      "metadata": {
        "id": "uvoqlX6ARucH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile going_modular/going_modular/train.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from going_modular.going_modular import data_setup, model_builder, engine, utils\n",
        "from torchvision import transforms\n",
        "\n",
        "# Setup hyper parameters\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Setup directories\n",
        "train_dir = \"going_modular/data/pizza_steak_sushi/train\"\n",
        "test_dir =  \"going_modular/data/pizza_steak_sushi/test\"\n",
        "\n",
        "# Setup target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create transforms\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "]\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir = train_dir,\n",
        "    test_dir = test_dir,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    transform = data_transform\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape = 3,\n",
        "    hidden_units = HIDDEN_UNITS,\n",
        "    output_shape = 3\n",
        ").to(device)\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "# Start training\n",
        "engine.train(model = model,\n",
        "             train_dataloader = train_dataloader,\n",
        "             test_dataloader = test_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             epochs = NUM_EPOCHS,\n",
        "             device = device)\n",
        "\n",
        "# Save model\n",
        "utils.save_model(model = model,\n",
        "                 target_dir = \"going_modular/models\",\n",
        "                 model_name = \"05_going_modular_script_mode_tinyvgg_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ddd598af3a8742309523b9165f97c313",
            "9bf667a88500445b85b17c67f0e1af92",
            "d8fd9656d3ee4069abfd559e35b91dd7",
            "a9f974adecf04f369141bc9a4290470d",
            "36b2085a2c064fe5abcba268a24d561a",
            "be57606dcea34a1cb4d0ab6a7a9b597d",
            "8a6563662a394120931fad6689ed0dcd",
            "45a44390a4964e2fbf1520fcb1d33b5f",
            "740a40924b8d400eb689fad010406e1b",
            "5099a2c86144414ab8001f48a9722c45",
            "347c24ae0e4848748074131952e2c48c"
          ]
        },
        "id": "RzduvRt6Rm2h",
        "outputId": "818e07de-b0d4-41df-a014-46735655dcfb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddd598af3a8742309523b9165f97c313"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train_loss: 1.0941, train_acc: 0.4336, test_loss: 1.0972, test_acc: 0.2604\n",
            "Epoch: 2, train_loss: 1.0736, train_acc: 0.4258, test_loss: 1.1510, test_acc: 0.2604\n",
            "Epoch: 3, train_loss: 1.1269, train_acc: 0.3047, test_loss: 1.1307, test_acc: 0.2604\n",
            "Epoch: 4, train_loss: 1.1048, train_acc: 0.4023, test_loss: 1.1322, test_acc: 0.2396\n",
            "Epoch: 5, train_loss: 1.0451, train_acc: 0.5352, test_loss: 1.0633, test_acc: 0.6042\n",
            "[INFO] saving model to going_modular/models/05_going_modular_script_mode_tinyvgg_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercises"
      ],
      "metadata": {
        "id": "-hTTLs47sAxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Turn the code to get the data (from section 1. Get Data above) into a Python script, such as get_data.py"
      ],
      "metadata": {
        "id": "iE41DT-6sM6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile going_modular/going_modular/get_data.py\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Set up path for data\n",
        "data_path = Path(\"going_modular/data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the data path does not exist, create it\n",
        "if image_path.is_dir():\n",
        "  print(f\"Directory {data_path} already exists\")\n",
        "else:\n",
        "  print(f\"Directory {data_path} does not exit, creating one...\")\n",
        "  data_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "# Download pizza steak sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza steak sushi data\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip pizza steak sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza_steak_sushi.zip  \")\n",
        "  zip_ref.extractall(image_path)\n",
        "\n",
        "# Remove zip file\n",
        "os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4rqgeALsC9q",
        "outputId": "2381ab6f-1893-4008-fd96-cfce8fbdc927"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory going_modular/data already exists\n",
            "Downloading pizza steak sushi data\n",
            "Unzipping pizza_steak_sushi.zip  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 going_modular/going_modular/get_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su_sJc2LtP0R",
        "outputId": "d8a9a5e2-2d8a-4a30-c267-685393cc3730"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory going_modular/data already exists\n",
            "Downloading pizza steak sushi data\n",
            "Unzipping pizza_steak_sushi.zip  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Use Python's argparse module to be able to send the train.py custom hyperparameter values for training procedures."
      ],
      "metadata": {
        "id": "mwtxenSSvWSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/train.py\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import data_setup, model_builder, engine, utils\n",
        "from torchvision import transforms\n",
        "\n",
        "# Create a parser\n",
        "parser = argparse.ArgumentParser(description=\"Get some hyperparameters.\")\n",
        "\n",
        "# Get an argument for num epochs\n",
        "parser.add_argument(\"--num_epochs\",\n",
        "                      default = 10,\n",
        "                      type = int,\n",
        "                      help = \"the number of epochs to train for\")\n",
        "\n",
        "# Get an arg for batch_size\n",
        "parser.add_argument(\"--batch_size\",\n",
        "                    default=32,\n",
        "                    type=int,\n",
        "                    help=\"number of samples per batch\")\n",
        "\n",
        "# Get an arg for hidden_units\n",
        "parser.add_argument(\"--hidden_units\",\n",
        "                    default=10,\n",
        "                    type=int,\n",
        "                    help=\"number of hidden units in hidden layers\")\n",
        "\n",
        "# Get an arg for learning_rate\n",
        "parser.add_argument(\"--learning_rate\",\n",
        "                    default=0.001,\n",
        "                    type=float,\n",
        "                    help=\"learning rate to use for model\")\n",
        "\n",
        "# Create an arg for training directory\n",
        "parser.add_argument(\"--train_dir\",\n",
        "                    default=\"/content/going_modular/data/pizza_steak_sushi/train\",\n",
        "                    type=str,\n",
        "                    help=\"directory file path to training data in standard image classification format\")\n",
        "\n",
        "# Create an arg for test directory\n",
        "parser.add_argument(\"--test_dir\",\n",
        "                    default=\"/content/going_modular/data/pizza_steak_sushi/test\",\n",
        "                    type=str,\n",
        "                    help=\"directory file path to testing data in standard image classification format\")\n",
        "\n",
        "# Get our arguments from the parser\n",
        "args = parser.parse_args()\n",
        "\n",
        "# Setup hyper parameters\n",
        "NUM_EPOCHS = args.num_epochs\n",
        "BATCH_SIZE = args.batch_size\n",
        "HIDDEN_UNITS = args.hidden_units\n",
        "LEARNING_RATE = args.learning_rate\n",
        "\n",
        "# Setup directories\n",
        "train_dir = args.train_dir\n",
        "test_dir = args.test_dir\n",
        "\n",
        "# Setup target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create transforms\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor()\n",
        "]\n",
        ")\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir = train_dir,\n",
        "    test_dir = test_dir,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    transform = data_transform\n",
        ")\n",
        "\n",
        "# Create model\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape = 3,\n",
        "    hidden_units = HIDDEN_UNITS,\n",
        "    output_shape = len(class_names)\n",
        ").to(device)\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "# Start training\n",
        "engine.train(model = model,\n",
        "             train_dataloader = train_dataloader,\n",
        "             test_dataloader = test_dataloader,\n",
        "             loss_fn = loss_fn,\n",
        "             optimizer = optimizer,\n",
        "             epochs = NUM_EPOCHS,\n",
        "             device = device)\n",
        "\n",
        "# Save model\n",
        "utils.save_model(model = model,\n",
        "                 target_dir = \"going_modular/models\",\n",
        "                 model_name = \"05_going_modular_script_mode_tinyvgg_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oQtpZ8PvLxf",
        "outputId": "ef3e51bc-1c5f-40d4-bc03-64dbeda43295"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "utils.save_model(model = model,\n",
        "                 target_dir = \"going_modular/models\",\n",
        "                 model_name = \"05_going_modular_script_mode_tinyvgg_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV9dNmeP37Mg",
        "outputId": "cab5d6ea-7eb5-4eab-c4c6-c266a4f18dec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] saving model to going_modular/models/05_going_modular_script_mode_tinyvgg_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 going_modular/going_modular/train.py --num_epochs 5 --batch_size 128 --hidden_units 128 --learning_rate 0.00"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu9mkSQm1Xre",
        "outputId": "bb0bcc40-c58c-4c37-e0ce-82e86791794f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0% 0/5 [00:00<?, ?it/s]Epoch: 1, train_loss: 1.0990, train_acc: 0.3379, test_loss: 1.1004, test_acc: 0.2533\n",
            " 20% 1/5 [00:31<02:05, 31.26s/it]Epoch: 2, train_loss: 1.0990, train_acc: 0.3342, test_loss: 1.1004, test_acc: 0.2533\n",
            " 40% 2/5 [01:01<01:32, 30.92s/it]Epoch: 3, train_loss: 1.0991, train_acc: 0.3317, test_loss: 1.1004, test_acc: 0.2533\n",
            " 60% 3/5 [01:32<01:01, 30.91s/it]Epoch: 4, train_loss: 1.0990, train_acc: 0.3354, test_loss: 1.1004, test_acc: 0.2533\n",
            " 80% 4/5 [02:03<00:30, 30.78s/it]Epoch: 5, train_loss: 1.0990, train_acc: 0.3329, test_loss: 1.1004, test_acc: 0.2533\n",
            "100% 5/5 [02:33<00:00, 30.78s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/going_modular/going_modular/train.py\", line 99, in <module>\n",
            "    utils.model_save(model = model,\n",
            "AttributeError: module 'utils' has no attribute 'model_save'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create a Python script to predict (such as predict.py) on a target image given a file path with a saved model."
      ],
      "metadata": {
        "id": "je7cK7gQ3_u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/predict.py\n",
        "import argparse\n",
        "import torch\n",
        "import model_builder\n",
        "from torchvision import transforms\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "parser = argparse.ArgumentParser(description=\"Get an image path\")\n",
        "\n",
        "# Get an argument for num epochs\n",
        "parser.add_argument(\"--image_path\",\n",
        "                      default = None,\n",
        "                      type = str,\n",
        "                      help = \"The path to a single image\")\n",
        "\n",
        "# Get our arguments from the parser\n",
        "args = parser.parse_args()\n",
        "image_path = args.image_path\n",
        "\n",
        "# Load the image\n",
        "import torchvision\n",
        "img = torchvision.io.read_image(image_path)\n",
        "\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = model_builder.TinyVGG(\n",
        "    input_shape = 3,\n",
        "    hidden_units = 10,\n",
        "    output_shape = 3)\n",
        "loaded_model.load_state_dict(torch.load(f=\"/content/going_modular/models/05_going_modular_script_mode_tinyvgg_model.pth\"))\n",
        "loaded_model = loaded_model.to(device)\n",
        "\n",
        "\n",
        "# Make prediction on a sigle image\n",
        "loaded_model.eval()\n",
        "with torch.inference_mode():\n",
        "  img = img / 255.\n",
        "\n",
        "  resize = transforms.Resize((64, 64))\n",
        "  img = resize(img)\n",
        "\n",
        "  batch = img.unsqueeze(0).to(device)\n",
        "\n",
        "  y_pred_logit = loaded_model(batch)\n",
        "\n",
        "  pred_label = torch.argmax(y_pred_logit, dim=1)\n",
        "\n",
        "class_names = [\"pizza\", \"steak\", \"sushi\"]\n",
        "print(class_names[pred_label])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWOeR93g4DEa",
        "outputId": "f1b64247-5245-41cc-abf4-6c76c8d90ee9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/going_modular/predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 going_modular/going_modular/predict.py --image_path \"/content/going_modular/data/pizza_steak_sushi/test/steak/100274.jpg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_jU4sbV5eqy",
        "outputId": "da7d6c71-1967-4910-9efc-1a7abc13865e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "steak\n"
          ]
        }
      ]
    }
  ]
}